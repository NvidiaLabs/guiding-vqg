{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(data.Dataset):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = 0\n",
    "        image = np.random.randn(512)\n",
    "        encoded_input_id = torch.tensor(list(range(self.max_input_len)))\n",
    "        encoded_input_attention_mask = torch.tensor([0]*self.max_input_len)\n",
    "        encoded_question_id = torch.tensor(list(range(self.max_q_len)))\n",
    "        encoded_question_attention_mask = torch.tensor([0]*self.max_q_len)\n",
    "        encoded_cat_obj_ids = torch.tensor(list(range(self.max_inference_len)))\n",
    "        encoded_cat_obj_attn_mask = torch.tensor([0]*self.max_inference_len)\n",
    "        rcnn_features = torch.tensor(0)\n",
    "        rcnn_locations = torch.tensor(0)\n",
    "\n",
    "        return image_id, torch.from_numpy(image), encoded_input_id, encoded_input_attention_mask, encoded_question_id, encoded_question_attention_mask, encoded_cat_obj_ids, encoded_cat_obj_attn_mask, rcnn_features, rcnn_locations\n",
    "\n",
    "    def __len__(self):\n",
    "        return 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    image_ids, images, encoded_input_ids, encoded_input_attention_masks, encoded_question_ids, encoded_question_attention_masks, encoded_cat_obj_ids, encoded_cat_obj_attn_mask, rcnn_features, rcnn_locations = list(zip(*data))\n",
    "\n",
    "    images = torch.stack(images).float()\n",
    "    input_ids = torch.stack(encoded_input_ids).long()\n",
    "    input_attention_masks = torch.stack(encoded_input_attention_masks).long()\n",
    "    question_ids = torch.stack(encoded_question_ids).long()\n",
    "    question_attention_masks = torch.stack(encoded_question_attention_masks).long()\n",
    "    inference_ids = torch.stack(encoded_cat_obj_ids).long()\n",
    "    inference_attention_masks = torch.stack(encoded_cat_obj_attn_mask).long()\n",
    "    rcnn_features = torch.stack(rcnn_features)\n",
    "    rcnn_locations = torch.stack(rcnn_locations)\n",
    "\n",
    "    return {\"images\": images,\n",
    "            \"image_ids\": image_ids,\n",
    "            \"question_ids\": question_ids,\n",
    "            \"question_attention_masks\": question_attention_masks,\n",
    "            \"input_ids\": input_ids,\n",
    "            \"input_attention_masks\": input_attention_masks,\n",
    "            \"inference_ids\": inference_ids,\n",
    "            \"inference_attention_masks\": inference_attention_masks,\n",
    "            \"rcnn_features\": rcnn_features,\n",
    "            \"rcnn_locations\": rcnn_locations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(dataset, tokenizer, batch_size, sampler=None,\n",
    "               shuffle=True, num_workers=1, max_examples=None,\n",
    "               indices=None):\n",
    "\n",
    "    vqg = VQGDataset(dataset, tokenizer, max_examples=max_examples,\n",
    "                     indices=indices)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset=vqg,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=shuffle,\n",
    "                                              sampler=sampler,\n",
    "                                              num_workers=num_workers,\n",
    "                                              collate_fn=collate_fn)\n",
    "    return data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}